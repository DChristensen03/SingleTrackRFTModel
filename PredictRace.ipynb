{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_abbreviation = \"baq\"\n",
    "track_name = \"Aqueduct\"\n",
    "race_date = \"20241003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_quality_dict = {\n",
    "    \"TRL\": 1,\n",
    "    \"MCL\": 1,\n",
    "    \"WMC\": 1,\n",
    "    \"MOC\": 1.5,\n",
    "    \"MSA\": 1.5,\n",
    "    \"MSW\": 2.5,\n",
    "    \"WCL\": 2,\n",
    "    \"CLM\": 2,\n",
    "    \"MST\": 2.5,\n",
    "    \"CLH\": 2.5,\n",
    "    \"CST\": 2.5,\n",
    "    \"SOC\": 2.5,\n",
    "    \"OCL\":\t2.75,\n",
    "    \"SHP\":\t3,\n",
    "    \"STR\":\t2.75,\n",
    "    \"AOC\": 3.25,\n",
    "    \"OCS\": 3.5,\n",
    "    \"OCH\":\t3.25,\n",
    "    \"ALW\":\t4,\n",
    "    \"HCP\":\t4,\n",
    "    \"SIM\":\t2,\n",
    "    \"SST\":\t3.5,\n",
    "    \"STK\": 5\n",
    "}\n",
    "\n",
    "race_types = {\n",
    "    \"AL\": \"ALW\",\n",
    "    \"MS\": \"MSW\",\n",
    "    \"CL\": \"CLM\",\n",
    "    \"OC\": \"AOC\",\n",
    "    \"MC\": \"MCL\",\n",
    "    \"SO\": \"SOC\",\n",
    "    \"MO\": \"MCL\", # MO is Maiden Optional Claiming but the simulcast data contains no definition for it\n",
    "    \"ST\": \"STK\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PP data for:  baq20241003ppsXML.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_27052\\518552168.py:102: RuntimeWarning: invalid value encountered in divide\n",
      "  f\"pp_normalized_position_{i}\": np.divide(float(pp_dict['positionfi']), float(pp_dict['fieldsize'])),\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 2: Load and Parse XML Data using pandas.read_xml\n",
    "def load_performance_data(file_path):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    print(\"Loading PP data for: \", os.path.basename(file_path))\n",
    "    \n",
    "    # Extract each Race element within EntryRaceCard and convert to a dictionary\n",
    "    races = []\n",
    "    for race in root.findall('.//racedata'):\n",
    "        race_dict = xmltodict.parse(ET.tostring(race))['racedata']\n",
    "        race_date = race_dict['race_date']\n",
    "        track_name = race_dict['track']\n",
    "\n",
    "        race_dict = extract_general_race_info(race_dict, race_date, track_name)\n",
    "\n",
    "        for entry in race.findall('.//horsedata'):\n",
    "            entry_dict = extract_entry_info(entry, race_date)\n",
    "            workout_dict = extract_workout_info(entry, race_date)\n",
    "            races.append({**race_dict, **entry_dict, **workout_dict})\n",
    "        \n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    df = pd.DataFrame(races)\n",
    "\n",
    "    return df\n",
    "\n",
    "def extract_general_race_info(race_dict, race_date, track_name):\n",
    "    race_id = f\"{race_date}_{race_dict['race']}_{track_name}\"\n",
    "    return {\n",
    "        \"race_id\": race_id,\n",
    "        \"course_type\": str(race_dict['surface']),\n",
    "        \"distance\": int(float(race_dict['distance'])),\n",
    "        \"race_type\": race_types[str(race_dict['stkorclm'])],\n",
    "        \"restriction_type\": \"S\" if \"state\" in str(race_dict['race_text']).lower() else \"None\",\n",
    "        \"purse\": float(race_dict['purse']),\n",
    "        \"number_of_run\": len(race_dict['horsedata']),\n",
    "    }\n",
    "\n",
    "def extract_entry_info(entry_root, race_date):\n",
    "    entry_dict = xmltodict.parse(ET.tostring(entry_root))['horsedata']\n",
    "\n",
    "    final_dict = {\n",
    "        \"horse_id\": f\"{entry_dict['horse_name']}_{entry_dict['program']}\",\n",
    "        \"gender\": str(entry_dict['sex']),\n",
    "        \"post_position\": int(entry_dict['pp']),\n",
    "        \"weight\": int(entry_dict['weight']),\n",
    "        \"equipment\": str(entry_dict['equip']),\n",
    "        \"medication\": str(entry_dict['med']),\n",
    "        \"jockey_win_percentage\": float(entry_dict['jockey']['stats_data']['stat']['wins']) / float(entry_dict['jockey']['stats_data']['stat']['starts']) if float(entry_dict['jockey']['stats_data']['stat']['starts']) != 0 else 0,\n",
    "        \"trainer_win_percentage\": float(entry_dict['trainer']['stats_data']['stat']['wins']) / float(entry_dict['trainer']['stats_data']['stat']['starts']) if float(entry_dict['trainer']['stats_data']['stat']['starts']) != 0 else 0,\n",
    "        \"trainer_jockey_win_percentage\": float(entry_dict['stats_data']['stat'][22]['wins']) / float(entry_dict['stats_data']['stat'][22]['starts']) if float(entry_dict['stats_data']['stat'][22]['starts']) != 0 else 0,\n",
    "    }\n",
    "\n",
    "    summaries = entry_root.findall('.//stats_data')\n",
    "    if summaries is list:\n",
    "        summary_dict = xmltodict.parse(ET.tostring(summaries[0]))['stat']['THIS_YEAR']\n",
    "        final_dict.update({\n",
    "            \"win_percentage_year\": float(summary_dict['wins']) / float(summary_dict['starts']),\n",
    "            \"otb_percentage_year\": (float(summary_dict['wins']) + float(summary_dict['places']) + float(summary_dict['shows'])) / float(summary_dict['starts']),\n",
    "        })\n",
    "\n",
    "\n",
    "    for i, pp in enumerate(entry_root.findall('.//ppdata')):\n",
    "        if i > 5:\n",
    "            break\n",
    "        pp_dict = xmltodict.parse(ET.tostring(pp))['ppdata']\n",
    "\n",
    "        race_type = str(pp_dict['racetype'])\n",
    "        race_quality = race_quality_dict[race_type] if str(race_type) in race_quality_dict.keys() else 1\n",
    "\n",
    "        if str(pp_dict['statebredr']) == 'S':\n",
    "            race_quality -= 1\n",
    "        if race_type == 'STK' and pp_dict['racegrade'] != 0:\n",
    "            race_quality += 1 + int(pp_dict['racegrade'])\n",
    "\n",
    "        if i == 0:\n",
    "            final_dict.update({\n",
    "                \"pp_layoff\": (datetime.strptime(race_date, '%Y%m%d') - datetime.strptime(pp_dict['racedate'][:10], '%Y%m%d')).days\n",
    "            })\n",
    "\n",
    "        bad_luck = False\n",
    "        long_comment = str(pp_dict['longcommen']).lower()\n",
    "        if long_comment is not None:\n",
    "            if any(['bump' in long_comment, 'stumbled' in long_comment, 'checked' in long_comment, 'steadied' in long_comment, 'stopped' in long_comment, 'squeezed' in long_comment, 'steady' in long_comment or 'steadied' in long_comment, 'head turned' in long_comment, 'unprepared start' in long_comment, 'wd' in long_comment or 'wide' in long_comment, 'bled' in long_comment]):\n",
    "                bad_luck = True\n",
    "\n",
    "        final_dict.update({\n",
    "            f\"pp_track_{i}\": str(pp_dict['trackcode']),\n",
    "            f\"pp_time_since_race_{i}\": (datetime.strptime(race_date, '%Y%m%d') - datetime.strptime(pp_dict['racedate'][:10], '%Y%m%d')).days,\n",
    "            f\"pp_course_type_{i}\": str(pp_dict['surface']),\n",
    "            f\"pp_distance_{i}\": int(pp_dict['distance']),\n",
    "            f\"pp_quality_{i}\": race_quality,\n",
    "            f\"pp_purse_{i}\": float(pp_dict['purse']),\n",
    "            f\"pp_normalized_position_{i}\": np.divide(float(pp_dict['positionfi']), float(pp_dict['fieldsize'])),\n",
    "            f\"pp_class_rating_{i}\": int(pp_dict['classratin']),\n",
    "            f\"pp_speed_rating_{i}\": int(pp_dict['speedfigur']),\n",
    "            f\"pp_pace_figure_{i}\": int(pp_dict['pacefigur2']),\n",
    "            f\"pp_bad_luck_{i}\": bad_luck,\n",
    "        })\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "def extract_workout_info(entry_root, race_date):\n",
    "    final_dict = {}\n",
    "    for i, workout in enumerate(entry_root.findall('.//workoutdata')):    \n",
    "        if i > 3:\n",
    "            return final_dict\n",
    "        workout_dict = xmltodict.parse(ET.tostring(workout))['workoutdata']\n",
    "        final_dict.update({\n",
    "            f\"workout_last_month_{i}\": True if int(workout_dict['days_back']) < 30 else False,\n",
    "            f\"workout_distance_{i}\": int(workout_dict['worktext'][0]) * 100,\n",
    "            f\"workout_course_type_{i}\": str(workout_dict['worktext'][1]),\n",
    "            f\"workout_time_{i}\": int(float(re.sub('\\D', '', get_substring_from_char(workout_dict['worktext'], ':'))) * 10),\n",
    "            f\"workout_rank_{i}\": int(workout_dict['ranking']) / int(workout_dict['rank_group']),\n",
    "        })\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "def get_substring_from_char(s, char):\n",
    "    pos = s.find(char) + 1\n",
    "    if pos != -1:\n",
    "        return s[pos:]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "performance_path = \"C:\\\\Users\\\\dylan\\\\OneDrive - Wayne State College\\\\Documents\\\\XML_PPs\"\n",
    "file_name = f'{track_abbreviation}{race_date}ppsXML.xml'  # Add your suffixes here\n",
    "\n",
    "# Load all past performance files\n",
    "performance_data = load_performance_data(performance_path + '\\\\' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_27052\\3537981293.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  performance_data.at[i, \"first_off_layoff\"] = False\n",
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_27052\\3537981293.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  performance_data.at[i, \"second_off_layoff\"] = False\n",
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_27052\\3537981293.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  performance_data.at[i, \"third_off_layoff\"] = False\n"
     ]
    }
   ],
   "source": [
    "# Go through each row and create new columns\n",
    "for i, row in performance_data.iterrows():\n",
    "    # Initialize new columns\n",
    "    performance_data.at[i, \"first_off_layoff\"] = False\n",
    "    performance_data.at[i, \"second_off_layoff\"] = False\n",
    "    performance_data.at[i, \"third_off_layoff\"] = False\n",
    "    \n",
    "    # Set if horse is off layoff\n",
    "    if row['pp_time_since_race_0'] > 45:\n",
    "        performance_data.at[i, 'first_off_layoff'] = True\n",
    "    elif row['pp_time_since_race_1'] - row['pp_time_since_race_0'] > 45:\n",
    "        performance_data.at[i, 'second_off_layoff'] = True\n",
    "    elif row['pp_time_since_race_2'] - row['pp_time_since_race_1'] > 45:\n",
    "        performance_data.at[i, 'third_off_layoff'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equipment  errored\n",
      "medication  errored\n",
      "pp_track_0  errored\n",
      "pp_track_2  errored\n",
      "workout_course_type_0  errored\n",
      "workout_course_type_1  errored\n",
      "workout_course_type_2  errored\n",
      "workout_course_type_3  errored\n",
      "pp_track_5  errored\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "performance_data.reset_index()\n",
    "\n",
    "# Drop unneeded columns\n",
    "horse_ids = performance_data['horse_id']\n",
    "performance_data = performance_data.drop(columns=['horse_id'])\n",
    "\n",
    "# Identify columns with missing values\n",
    "columns_with_missing = performance_data.columns[performance_data.isnull().any()]\n",
    "\n",
    "# Impute only columns with missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputed_array = imputer.fit_transform(performance_data[columns_with_missing])\n",
    "\n",
    "# Convert the imputed array back to a DataFrame with original column names\n",
    "imputed_data = pd.DataFrame(imputed_array, columns=columns_with_missing)\n",
    "\n",
    "# Combine the imputed columns with the rest of the data\n",
    "data = performance_data.copy()\n",
    "data[columns_with_missing] = imputed_data\n",
    "\n",
    "# Get correct column types\n",
    "data = data.infer_objects()\n",
    "\n",
    "# Use LabelEncoder on string columns\n",
    "label_encoders = pickle.load(open(f\"Models\\\\{track_name}\\\\label_encoders.pkl\", \"rb\"))\n",
    "for col in data.columns:\n",
    "    if col == \"race_id\" or col == \"horse_id\":\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])\n",
    "    elif data[col].dtype == 'object':\n",
    "        try:\n",
    "            data[col] = label_encoders[col].transform(data[col])\n",
    "        except:\n",
    "            data[col] = LabelEncoder().fit_transform(data[col])\n",
    "            print(col, \" errored\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(f\"Models\\\\{track_name}\\\\{track_name}_Model.pkl\", \"rb\"))\n",
    "\n",
    "feature_names = model.feature_names_in_\n",
    "\n",
    "# Reorder the columns of merged_data_imputed to match the order of feature_names\n",
    "data = data[feature_names]\n",
    "\n",
    "# Now make the prediction\n",
    "y_predict = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_normalized_position = model.predict(data)\n",
    "predicted_finish_position = ((predicted_normalized_position * data['number_of_run']) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame by concatenating the series\n",
    "results_df = pd.concat([performance_data['race_id'], horse_ids, predicted_finish_position], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
